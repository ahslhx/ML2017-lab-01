{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  14.03663964  -18.00547854   -3.40369131 ...,  -22.83144933  -30.1269436\n",
      "   -32.49132747]\n",
      " [  55.70095096  -71.45031167  -13.50671155 ...,  -90.60098941\n",
      "  -119.55136351 -128.93383915]\n",
      " [  12.25420921  -15.71906857   -2.97147654 ...,  -19.93221767\n",
      "   -26.30129997  -28.36544461]\n",
      " ..., \n",
      " [  23.3943994   -30.0091309    -5.67281885 ...,  -38.05241555\n",
      "   -50.21157267  -54.15221244]\n",
      " [  23.50580131  -30.15203152   -5.69983227 ...,  -38.23361753  -50.4506754\n",
      "   -54.41008012]\n",
      " [  26.62505456  -34.15324898   -6.45620812 ...,  -43.30727294\n",
      "   -57.14555176  -61.63037511]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-702edfc92a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-702edfc92a57>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mloss_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mloss_validation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m#update W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "LEARNING_RATE = 0.2\n",
    "NUM_ITERATIONS = 500\n",
    "PATH = \"./data/housing_scale.txt\"\n",
    "\n",
    "#load data\n",
    "def get_data(path):\n",
    "    data = load_svmlight_file(path)\n",
    "    return data[0],  data[1]\n",
    "\n",
    "#compute loss\n",
    "def compute_loss(X,y,W):\n",
    "    m = X.shape[0]\n",
    "    pred = np.dot(W,X.transpose())\n",
    "    diffY = pred-y\n",
    "    loss = np.dot(diffY,diffY.transpose())/(2*m)\n",
    "    return loss\n",
    "\n",
    "#cmpute gradient\n",
    "def compute_gradient(X,y,initial_W):\n",
    "    m = X.shape[0]\n",
    "    W = initial_W\n",
    "    pred = np.dot(W,X.transpose())\n",
    "    gradient = np.dot((pred-y),X)/m\n",
    "    return gradient\n",
    "\n",
    "def main():\n",
    "    path = PATH\n",
    "    X,y = get_data(path)\n",
    "    X0 = np.ones((len(y),1))\n",
    "    X = X.todense()\n",
    "    X = np.column_stack((X0,X))\n",
    "    #print(X.shape)\n",
    "\n",
    "    #divide dataset\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.3)\n",
    "    num_features = X_train.shape[1]\n",
    "    num_train = X_train.shape[0]\n",
    "    num_validation = X_validation.shape[0]\n",
    "    #initial W in three ways\n",
    "    initial_W_zero = np.zeros(num_features)\n",
    "    initial_W_random = np.random.random(num_features)\n",
    "    initial_W_normal = np.random.normal(size=num_features)\n",
    "    \n",
    "    #perform gradient descent to learn W and update W\n",
    "    learning_rate = LEARNING_RATE\n",
    "    num_iterations = NUM_ITERATIONS\n",
    "    W = initial_W_random\n",
    "    loss_train = np.zeros(num_iterations)\n",
    "    loss_validation = np.zeros(num_iterations)\n",
    "\n",
    "    for i in range(0,num_iterations):\n",
    "        loss_train[i] = compute_loss(X_train,y_train,W)\n",
    "        loss_validation[i] = compute_loss(X_validation,y_validation,W)\n",
    "        #update W\n",
    "        G = compute_gradient(X_train,y_train,W)\n",
    "        W = W - learning_rate*G\n",
    "  \n",
    "    # plot\n",
    "    plt.figure(1)\n",
    "    plt.plot(loss_train,label=\"Training Loss\")\n",
    "    plt.plot(loss_validation,label=\"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Linear Regression\")\n",
    "    \n",
    "    lr_arr = np.array([0.003,0.05,0.1,0.2,0.4])\n",
    "    color = np.array(['r','g','b','y','c'])\n",
    "    num_iterations = NUM_ITERATIONS\n",
    "    plt.figure(2)\n",
    "    for j in np.arange(lr_arr.size):\n",
    "        loss_train = np.zeros(num_iterations)\n",
    "        W = initial_W_normal\n",
    "        for i in range(0,num_iterations):\n",
    "            loss_train[i] = compute_loss(X_train,y_train,W)\n",
    "            G = compute_gradient(X_train,y_train,W)\n",
    "            W = W - lr_arr[j]*G\n",
    "        label = 'lr = ' + str(lr_arr[j])\n",
    "        plt.plot(loss_train,c=color[j],label=label)\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Linear Regression\")\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
